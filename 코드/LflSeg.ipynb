{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bVNbJqT0cyLC"},"outputs":[],"source":["# reference : https://github.com/IyatomiLab/LeafGAN"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1653746195314,"user":{"displayName":"배정준","userId":"09279205626682241026"},"user_tz":-540},"id":"lZX5JNeuNAvE","outputId":"c0b99ee0-f22a-4ff7-d771-257c46fb0e80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat May 28 13:56:35 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["import numpy as np\n","import shutil\n","from glob import glob\n","import os\n","from natsort import natsorted\n","import pandas as pd"],"metadata":{"id":"1l2pky8EZvD_","executionInfo":{"status":"ok","timestamp":1653746195733,"user_tz":-540,"elapsed":423,"user":{"displayName":"배정준","userId":"09279205626682241026"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!unzip -qq /content/drive/MyDrive/4-1_Capstone/CapstoneDataset/images_concatenate.zip -d /content/capstone_images\n","capstone_images = natsorted(glob(os.path.join(\"/content/capstone_images\", '*')))\n","capstone_label_df = pd.read_csv(\"/content/drive/MyDrive/4-1_Capstone/CapstoneDataset/Capstone_labels.csv\")\n","\n","SAMPLES = 1000\n","os.system(\"unzip -qq /content/drive/MyDrive/4-1_Capstone/AI_HubDataset/images\" + str(SAMPLES) + \".zip -d /content/aihub_images\")\n","aihub_images = natsorted(glob(os.path.join(\"/content/aihub_images/images\" + str(SAMPLES), '*')))\n","aihub_label_df = pd.read_csv(\"/content/aihub_images/AI_Label_\" + str(SAMPLES)  +\".csv\")\n","\n","images = capstone_images + aihub_images\n","label_df = pd.concat([capstone_label_df, aihub_label_df]).fillna(0.).reset_index(drop = True)"],"metadata":{"id":"kEDkoByqZ9xw","executionInfo":{"status":"ok","timestamp":1653746237695,"user_tz":-540,"elapsed":41964,"user":{"displayName":"배정준","userId":"09279205626682241026"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# !rm -rf /content/dataset"],"metadata":{"id":"b5YaWu-Dfclo","executionInfo":{"status":"ok","timestamp":1653746237696,"user_tz":-540,"elapsed":5,"user":{"displayName":"배정준","userId":"09279205626682241026"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19325,"status":"ok","timestamp":1653746257421,"user":{"displayName":"배정준","userId":"09279205626682241026"},"user_tz":-540},"outputId":"eafbad53-a23d-4726-9cd6-8aa4f70e3b77","id":"lHsL1rxC-gOp"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'LeafGAN'...\n","remote: Enumerating objects: 239, done.\u001b[K\n","remote: Counting objects: 100% (63/63), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 239 (delta 51), reused 51 (delta 51), pack-reused 176\u001b[K\n","Receiving objects: 100% (239/239), 5.21 MiB | 26.93 MiB/s, done.\n","Resolving deltas: 100% (127/127), done.\n","/content/LeafGAN\n","\u001b[K     |████████████████████████████████| 676 kB 7.8 MB/s \n","\u001b[K     |████████████████████████████████| 47.8 MB 91.5 MB/s \n","\u001b[K     |████████████████████████████████| 38.1 MB 5.8 MB/s \n","\u001b[31mERROR: Could not find a version that satisfies the requirement skimage>=0.16.1 (from versions: 0.0)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for skimage>=0.16.1\u001b[0m\n","\u001b[?25h"]}],"source":["!git clone https://github.com/IyatomiLab/LeafGAN\n","%cd /content/LeafGAN\n","!pip install -r requirements.txt -qq\n","!pip install dominate -qq"]},{"cell_type":"code","source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/4-1_Capstone/\")\n","from utils import get_disease_healthy_map \n","disease_healthy_map = get_disease_healthy_map()"],"metadata":{"id":"v-fPDKs89EPb","executionInfo":{"status":"ok","timestamp":1653746238098,"user_tz":-540,"elapsed":405,"user":{"displayName":"배정준","userId":"09279205626682241026"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"01etqnOuZlhU","executionInfo":{"status":"ok","timestamp":1653746354297,"user_tz":-540,"elapsed":305,"user":{"displayName":"배정준","userId":"09279205626682241026"}}},"outputs":[],"source":["import shutil\n","import numpy as np\n","\n","def visualize(disease_label, threshold = 0.35):\n","    global images, SAMPLES\n","    healthy_label = disease_healthy_map[disease_label]\n","\n","    healthy_images = list(filter(lambda f : f.split('/')[-1].split('_')[0] == healthy_label, images))\n","    disease_images = list(filter(lambda f : f.split('/')[-1].split('_')[0] == disease_label, images))\n","    \n","    if os.path.exists(\"/content/dataset\"):\n","        os.system(\"rm -rf /content/dataset\")\n","        \n","    os.mkdir(\"/content/dataset\")\n","    os.mkdir(\"/content/dataset/trainA\")\n","    os.mkdir(\"/content/dataset/testA\")\n","    os.mkdir(\"/content/dataset/trainB\")\n","    os.mkdir(\"/content/dataset/testB\")\n","\n","    healthy_len = len(healthy_images)\n","    disease_len = len(disease_images)\n","\n","    healthy_images = np.array(healthy_images)\n","    disease_images = np.array(disease_images)\n","\n","    from sklearn.model_selection import train_test_split\n","    train_A_i, test_A_i, _, _ = train_test_split(list(range(healthy_len)), list(range(healthy_len)), random_state=0)\n","    train_B_i, test_B_i, _, _ = train_test_split(list(range(disease_len)), list(range(disease_len)), random_state=0)\n","\n","    import shutil\n","    for image in healthy_images[train_A_i]:\n","        file_name = image.split('/')[-1]\n","        dst = os.path.join(\"/content/dataset/trainA\", file_name)\n","\n","        shutil.move(image, dst)\n","\n","    for image in healthy_images[test_A_i]:\n","        file_name = image.split('/')[-1]\n","        dst = os.path.join(\"/content/dataset/testA\", file_name)\n","\n","        shutil.move(image, dst)\n","\n","    for image in disease_images[train_B_i]:\n","        file_name = image.split('/')[-1]\n","        dst = os.path.join(\"/content/dataset/trainB\", file_name)\n","\n","        shutil.move(image, dst)\n","\n","    for image in disease_images[test_B_i]:\n","        file_name = image.split('/')[-1]\n","        dst = os.path.join(\"/content/dataset/testB\", file_name)\n","\n","        shutil.move(image, dst)\n","\n","    # os.system(f\"python prepare_mask.py --source /content/dataset --pretrain_path /content/drive/MyDrive/4-1_Capstone/LFLSeg_resnet101.pth --image_size 224 --threshold {threshold}\")\n","\n","    # from glob import glob\n","    # from PIL import Image\n","    # import matplotlib.pyplot as plt\n","\n","    # imgs1      = glob(\"/content/dataset/testA/*\")\n","    # imgs1_mask = glob(\"/content/dataset/testA_mask/*\")\n","\n","    # cnt = 0\n","    # for img1, img1_mask in zip(imgs1, imgs1_mask):    \n","    #     plt.subplot(1, 2, 1)\n","    #     img1 = Image.open(img1)\n","    #     plt.imshow(img1)\n","        \n","    #     plt.subplot(1, 2, 2)\n","    #     img1_mask = Image.open(img1_mask)\n","    #     plt.imshow(img1_mask)\n","    #     plt.show()\n","        # if np.array(img1_mask).sum() == 0: cnt+=1\n"]},{"cell_type":"code","source":["visualize('47', threshold = '.35')"],"metadata":{"id":"IrXu1ylf_J3n","executionInfo":{"status":"ok","timestamp":1653746732551,"user_tz":-540,"elapsed":1065,"user":{"displayName":"배정준","userId":"09279205626682241026"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import argparse\n","from pathlib import Path\n","\n","import cv2\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from PIL import Image\n","from torchvision import models, transforms\n","from tqdm import tqdm\n","\n","from models.grad_cam import GradCAM\n","\n","\n","def parse_args() -> argparse.Namespace:\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--source\", type=str, default=None, help=\"leaf GAN's dataset\")\n","    parser.add_argument(\n","        \"--threshold\",\n","        \"-t\",\n","        type=float,\n","        default=0.35,\n","        help=\"heatmap threshold\",\n","    )\n","    parser.add_argument(\n","        \"--pretrain_path\",\n","        \"-p\",\n","        type=str,\n","        default=None,\n","        help=\"pretrain model path of LFLSeg \",\n","    )\n","    parser.add_argument(\"--image_size\", \"-i\", type=int, help=\"size of image\")\n","    args = parser.parse_args()\n","    return args\n","\n","\n","class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, paths, image_size):\n","        self.paths = paths\n","        self.transform = transforms.Compose(\n","            [\n","                transforms.Resize((image_size, image_size)),\n","                transforms.ToTensor(),\n","                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","            ]\n","        )\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def __getitem__(self, idx):\n","        img = Image.open(self.paths[idx])\n","        return self.transform(img)\n","\n","\n","def get_heatmap(model, loader, device):\n","    heatmaps = []\n","    for img in tqdm(loader):\n","        img = img.to(device)\n","        with torch.enable_grad():\n","            _ = model.forward(img)\n","            model.backward(idx=0)\n","        heatmap = model.generate(target_layer=\"layer4.2\")\n","        heatmaps.append(heatmap)\n","    return heatmaps\n","\n","def visualize_heatmap(heatmaps, image_size, paths):\n","    import matplotlib.pyplot as plt\n","    for heatmap, p in zip(heatmaps, paths):\n","        mask = cv2.resize(heatmap, dsize=(image_size, image_size))\n","        p = Image.open(p)\n","        plt.figure(figsize=(15, 3))\n","\n","        thresholds = [0.01, 0.05, 0.1, 0.35]\n","        plt.subplot(1, len(thresholds) + 1, 1)\n","        plt.imshow(p)\n","        for i, threshold in enumerate(thresholds):\n","            mask_ = (mask >= threshold).astype(int)\n","            mask_ = np.repeat(mask_[:, :, np.newaxis], 3, axis=2) * 255\n","            mask_img = Image.fromarray(mask_.astype(np.uint8))\n","            plt.subplot(1, len(thresholds) + 1, i+2)\n","            plt.imshow(mask_img)\n","            plt.title(threshold)\n","\n","        plt.show()\n","            # mask_img.save(out_dir / p.name)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# setting LFLSeg Model\n","segResNet = models.resnet101()\n","num_ftrs = segResNet.fc.in_features\n","segResNet.fc = nn.Linear(num_ftrs, 3)\n","pretrain_path = \"/content/drive/MyDrive/4-1_Capstone/LFLSeg_resnet101.pth\"\n","segResNet.load_state_dict(torch.load(pretrain_path), strict=True)\n","segResNet.to(device)\n","segResNet.eval()\n","\n","netLFLSeg = GradCAM(model=segResNet)\n","\n","# setup mask data folder\n","source = \"/content/dataset\"\n","data_root = Path(source)\n","dataset_dirs = [p for p in data_root.glob(\"*\") if \"mask\" not in str(p)]\n","mask_dataset_dirs = []\n","\n","for data_dir in dataset_dirs:\n","    out_dir = data_root / f\"{data_dir.name}_mask\"\n","    out_dir.mkdir(exist_ok=True)\n","    mask_dataset_dirs.append(out_dir)\n","\n","# get_mask\n","image_size = 224\n","for source_dir, out_dir in zip(dataset_dirs, mask_dataset_dirs):\n","    print(f\"##### {source_dir.name} #####\")\n","    paths = list(source_dir.glob(\"*\"))\n","    loader = torch.utils.data.DataLoader(\n","        MyDataset(paths, image_size),\n","        shuffle=False,\n","        batch_size=1,\n","        num_workers=1,\n","    )\n","    heatmaps = get_heatmap(netLFLSeg, loader, device)\n","    visualize_heatmap(heatmaps, 224, paths = paths)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vz5Qz4dS5NQpu1Zd6hfkv-yXvN2W5Ajo"},"id":"cjiXIDk8_RMA","outputId":"cc8de45d-8c58-44ed-96a7-b6f860a78756","executionInfo":{"status":"error","timestamp":1653746792417,"user_tz":-540,"elapsed":56435,"user":{"displayName":"배정준","userId":"09279205626682241026"}}},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[""],"metadata":{"id":"NLRERJKGDaGP"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"LflSeg.ipynb","provenance":[],"mount_file_id":"1B7c3kSnyopfoxFhsT2KMJf4aN5367pvw","authorship_tag":"ABX9TyM+G30P3wSyLR1ni6feNIF1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}